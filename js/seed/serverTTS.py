import time
start = time.time()
import g2pk
g2p = g2pk.G2p()

import re, os
import sys
from unicodedata import normalize
# import IPython

from fastapi import FastAPI, Form
from pydantic import BaseModel 
from fastapi.middleware.cors import CORSMiddleware

# ğŸš¨
# sys.path.remove("")
# sys.path.remove("/home/kseek/TTS4note/TTS")
#sys.path.remove("/home/kseek/seedBox/NLP/jupyter/kospeech")
# sys.path.remove("/home/kseek/boxboxbox/g2pK")
# sys.path.remove("/home/kseek/.local/lib/python3.8/site-packages")
# sys.path.remove("/home/kseek/TTS")
#sys.path.remove("/home/aiserver/ai/STT/kospeech")
#print("ğŸš¨ module pathğŸš¨")
#for i in sys.path:
#  print(i)
#print("\n")
# ğŸš¨

start_synthesizer = time.time()
from TTS.utils.synthesizer import Synthesizer
# ì´ ì¹œêµ¬ì˜ initì—ì„œ ì‹œê°„ì„ ë§ì´ ë¨¹ëŠ”ê±°ì•„ë‹Œê°€.. -> ì•„ë‹˜.
# synthesizer.pyì˜ torchê°€ ê°€ì¥ ì˜¤ëœì‹œê°„ì„ ì¡ìŒ. ì•½ 0.5ì´ˆ, ë‚˜ë¨¸ì§€ëŠ” 0.45, 0.02 ì •ë„..
# print("ğŸ‘‰ import synthesizer : ", time.time()-start_synthesizer);

# print("ğŸ‘‰ g2p load end : ", time.time()-start);

def normalize_text(text):
    text = text.strip()

    for c in ",;:":
        text = text.replace(c, ".")
    # text = remove_duplicated_punctuations(text)

    text = jamo_text(text)
    
    # g2p ì•ˆì“°ë©´ ì´ë¶€ë¶„ì„ ì£¼ì„í•˜ì„¸ìš”
    init_g2pk_time = time.time()
    
    text = g2p.idioms(text)
    # print("ğŸ—£ g2p.idioms : ", time.time()-init_g2pk_time);
    text = g2pk.english.convert_eng(text, g2p.cmu)
    # print("ğŸ—£ g2p convert eng : ", time.time()-init_g2pk_time);
    text = g2pk.utils.annotate(text, g2p.mecab)
    # print("ğŸ—£ g2pk.utils.annotate : ", time.time()-init_g2pk_time);
    text = g2pk.numerals.convert_num(text)
    # print("ğŸ—£ g2pk.numerals.convert_num : ", time.time()-init_g2pk_time);
    # g2p
    
    text = re.sub("/[PJEB]", "", text)

    text = alphabet_text(text)

    # remove unreadable characters
#    print("âœ before ",text);
    text = normalize("NFD", text)
    text = "".join(c for c in text if c in symbols)
    text = normalize("NFC", text)
#    print("âœ after ",text);

    text = text.strip()
    if len(text) == 0:
        return ""

    # only single punctuation
    if text in '.!?':
        return punctuation_text(text)

    # append punctuation if there is no punctuation at the end of the text
    if text[-1] not in '.!?':
        text += ' '

    return text


def remove_duplicated_punctuations(text):
    text = re.sub(r"[.?!]+\?", "?", text)
    text = re.sub(r"[.?!]+!", "!", text)
    text = re.sub(r"[.?!]+\.", ".", text)
    return text


def split_text(text):
    # text = remove_duplicated_punctuations(text)

    texts = []

    # ?ì™€ !ë¡œ ë‚˜ëˆ ì§€ëŠ”ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´
    # for subtext in re.findall(r'[^.!?\n]*[.!?\n]', text):
    for subtext in re.findall(r'[^.\n]*[.\n]', text):
        texts.append(subtext.strip())

    # print("ğŸ’» split_text : ",texts)
    return texts


def alphabet_text(text):
    text = re.sub(r"(a|A)", "ì—ì´", text)
    text = re.sub(r"(b|B)", "ë¹„", text)
    text = re.sub(r"(c|C)", "ì”¨", text)
    text = re.sub(r"(d|D)", "ë””", text)
    text = re.sub(r"(e|E)", "ì´", text)
    text = re.sub(r"(f|F)", "ì—í”„", text)
    text = re.sub(r"(g|G)", "ì¥", text)
    text = re.sub(r"(h|H)", "ì—ì´ì¹˜", text)
    text = re.sub(r"(i|I)", "ì•„ì´", text)
    text = re.sub(r"(j|J)", "ì œì´", text)
    text = re.sub(r"(k|K)", "ì¼€ì´", text)
    text = re.sub(r"(l|L)", "ì—˜", text)
    text = re.sub(r"(m|M)", "ì— ", text)
    text = re.sub(r"(n|N)", "ì—”", text)
    text = re.sub(r"(o|O)", "ì˜¤", text)
    text = re.sub(r"(p|P)", "í”¼", text)
    text = re.sub(r"(q|Q)", "í", text)
    text = re.sub(r"(r|R)", "ì•Œ", text)
    text = re.sub(r"(s|S)", "ì—ìŠ¤", text)
    text = re.sub(r"(t|T)", "í‹°", text)
    text = re.sub(r"(u|U)", "ìœ ", text)
    text = re.sub(r"(v|V)", "ë¸Œì´", text)
    text = re.sub(r"(w|W)", "ë”ë¸”ìœ ", text)
    text = re.sub(r"(x|X)", "ì—‘ìŠ¤", text)
    text = re.sub(r"(y|Y)", "ì™€ì´", text)
    text = re.sub(r"(z|Z)", "ì§€", text)

    return text


def punctuation_text(text):
    # ë¬¸ì¥ë¶€í˜¸
    text = re.sub(r"!", "ëŠë‚Œí‘œ", text)
    text = re.sub(r"\?", "ë¬¼ìŒí‘œ", text)
    text = re.sub(r"\.", "ë§ˆì¹¨í‘œ", text)

    return text


def jamo_text(text):
    # ê¸°ë³¸ ìëª¨ìŒ
    text = re.sub(r"ã„±", "ê¸°ì—­", text)
    text = re.sub(r"ã„´", "ë‹ˆì€", text)
    text = re.sub(r"ã„·", "ë””ê·¿", text)
    text = re.sub(r"ã„¹", "ë¦¬ì„", text)
    text = re.sub(r"ã…", "ë¯¸ìŒ", text)
    text = re.sub(r"ã…‚", "ë¹„ì", text)
    text = re.sub(r"ã……", "ì‹œì˜·", text)
    text = re.sub(r"ã…‡", "ì´ì‘", text)
    text = re.sub(r"ã…ˆ", "ì§€ì’", text)
    text = re.sub(r"ã…Š", "ì¹˜ì“", text)
    text = re.sub(r"ã…‹", "í‚¤ì”", text)
    text = re.sub(r"ã…Œ", "í‹°ì•", text)
    text = re.sub(r"ã…", "í”¼ì–", text)
    text = re.sub(r"ã…", "íˆì—", text)
    text = re.sub(r"ã„²", "ìŒê¸°ì—­", text)
    text = re.sub(r"ã„¸", "ìŒë””ê·¿", text)
    text = re.sub(r"ã…ƒ", "ìŒë¹„ì", text)
    text = re.sub(r"ã…†", "ìŒì‹œì˜·", text)
    text = re.sub(r"ã…‰", "ìŒì§€ì’", text)
    text = re.sub(r"ã„³", "ê¸°ì—­ì‹œì˜·", text)
    text = re.sub(r"ã„µ", "ë‹ˆì€ì§€ì’", text)
    text = re.sub(r"ã„¶", "ë‹ˆì€íˆì—", text)
    text = re.sub(r"ã„º", "ë¦¬ì„ê¸°ì—­", text)
    text = re.sub(r"ã„»", "ë¦¬ì„ë¯¸ìŒ", text)
    text = re.sub(r"ã„¼", "ë¦¬ì„ë¹„ì", text)
    text = re.sub(r"ã„½", "ë¦¬ì„ì‹œì˜·", text)
    text = re.sub(r"ã„¾", "ë¦¬ì„í‹°ì•", text)
    text = re.sub(r"ã„¿", "ë¦¬ì„í”¼ì", text)
    text = re.sub(r"ã…€", "ë¦¬ì„íˆì—", text)
    text = re.sub(r"ã…„", "ë¹„ìì‹œì˜·", text)
    text = re.sub(r"ã…", "ì•„", text)
    text = re.sub(r"ã…‘", "ì•¼", text)
    text = re.sub(r"ã…“", "ì–´", text)
    text = re.sub(r"ã…•", "ì—¬", text)
    text = re.sub(r"ã…—", "ì˜¤", text)
    text = re.sub(r"ã…›", "ìš”", text)
    text = re.sub(r"ã…œ", "ìš°", text)
    text = re.sub(r"ã… ", "ìœ ", text)
    text = re.sub(r"ã…¡", "ìœ¼", text)
    text = re.sub(r"ã…£", "ì´", text)
    text = re.sub(r"ã…", "ì• ", text)
    text = re.sub(r"ã…’", "ì–˜", text)
    text = re.sub(r"ã…”", "ì—", text)
    text = re.sub(r"ã…–", "ì˜ˆ", text)
    text = re.sub(r"ã…˜", "ì™€", text)
    text = re.sub(r"ã…™", "ì™œ", text)
    text = re.sub(r"ã…š", "ì™¸", text)
    text = re.sub(r"ã…", "ì›Œ", text)
    text = re.sub(r"ã…", "ì›¨", text)
    text = re.sub(r"ã…Ÿ", "ìœ„", text)
    text = re.sub(r"ã…¢", "ì˜", text)

    return text


def normalize_multiline_text(long_text):
    texts = split_text(long_text)
    # print(texts)
    normalized_texts = [normalize_text(text).strip() for text in texts]
    # print(normalized_texts)
    return [text for text in normalized_texts if len(text) > 0]

# 3. í•™ìŠµí•œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
syn_start = time.time();

synthesizer = Synthesizer(
# "/home/aiserver/ai/TTSmodel/glowtts_training_700_1/best_model.pth.tar",
# "/home/aiserver/ai/TTSmodel/glowtts_training_700_1/config.json",
   "/home/aiserver/ai/TTSmodel/0511_training/glowtts_checkpoint_30000.pth.tar",
   "/home/aiserver/ai/TTSmodel/0511_training/glowtts_config.json",
    None,
#   "/home/aiserver/ai/TTSmodel/hifigan_training_700_2/best_model_307123.pth.tar",
#   "/home/aiserver/ai/TTSmodel/hifigan_training_700_1/config.json",
  "/home/aiserver/ai/TTSmodel/0511_training/a4000_best_model_315313.pth.tar",
  "/home/aiserver/ai/TTSmodel/0511_training/a4000_config.json",
    # None,
    # None,
)

print("ğŸ‘‰ only Synthesizer end : ",time.time()-syn_start) # ì—¬ê¸°ê¹Œì§€ 0.5ì´ˆ
# symbols_start = time.time();
symbols = synthesizer.tts_config.characters.characters
# print(symbols)
# print("ğŸ‘‰ symbol end : ",time.time()-symbols_start)

app = FastAPI()

origins = ["*"]
origins=[
    "http://127.0.0.1",
    "http://localhost",
]
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
#    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)



# class Item(BaseModel):
#     text: str

#class text(BaseModel):
    # text: str
#    pass

#class text(BaseModel):
#    text: str

@app.post("/TTS/")
#@app.get("/TTS/")
#def makeTTS(text: str, fileName: str):
async def makeTTS(text: str=Form(...), fileName: str=Form(...)):
    makeTTSTime = time.time()
    # print(type(text))
    # if(text_str):
    #     print(type(text_str))
    if(text):
        print("inpurt text : ",text)
        print("ğŸ™Šinitalize Time: ",time.time()-makeTTSTime)

        texts = "ìƒ˜í”Œë¬¸ì¥ ì…ë‹ˆë‹¤"
        # texts = text+".\n"
        texts = text+"\n"
        # print(texts)
        print(fileName)

        import soundfile as sf
        inference_start = time.time();

        normalize_multiline_text(texts)
        # print("normalized end")
        # print("type normalize text : ",type(normalize_multiline_text(texts)))

        # list to str
        texts = "".join(map(str,normalize_multiline_text(texts)))

        wav = synthesizer.tts(texts, None, None)
        print("Inference : ",time.time()-inference_start); # 0.2 sec
        # print("tts end")
        output_name = '/home/aiserver/ai/TTS/soundData/'+fileName+".wav"
#        output_name = '/home/aiserver/ai/TTS/soundData/0.wav'
        # output_name = '/usr/share/nginx/demo/TTS/audio/0.wav'
        sf.write(output_name, wav, 22050)
        print("output time : ",time.time()-inference_start)
#       print("ğŸ™Šoutput Time : ",time.time()-makeTTSTime) # 0.28 sec

        # os.system("whoami")
        cmd = "cp /home/aiserver/ai/TTS/soundData/"+fileName+".wav /home/aiserver/ai/demo/TTS/audio/"+fileName+".wav"
        os.system(cmd)
#        os.system("cp /home/aiserver/ai/TTS/soundData/0.wav /home/aiserver/ai/demo/TTS/audio/0.wav")
#       print("copy time : ",time.time()-inference_start)

        # for text in Synthesizer.normalize_multiline_text(texts):
        #     wav = synthesizer.tts(text, None, None)
        #     output_name = '/home/kseek/boxboxbox/TTS/soundData/sample.wav'
        #     sf.write(output_name, wav, 22050)
        #     i+=1
        # print("Inference : ",time.time()-inference_start); # 0.2ì´ˆ
        print("ğŸ‘‰ total time : ",time.time()-makeTTSTime);
#        texts += "123";
        return texts

'''
# 4. ìŒì„± í•©ì„±
texts = """
ì´ì œ ë³¸ê²©ì ìœ¼ë¡œ ì‹œì‘í•´ ë³¼ê¹Œìš”? ì²«ë²ˆì§¸ ë¬¸ì œ ë³´ì—¬ì£¼ì„¸ìš”! ë¬¸ì œ ë‚˜ê°‘ë‹ˆë‹¤.  ì •ë‹µì€ ì²œì‚¬ì˜€ìŠµë‹ˆë‹¤! 1ë“± ê·¸ ì˜ê´‘ì˜ ì£¼ì¸ê³µì€ ë°”ë¡œ í™ê¸¸ë™ë‹˜! ì¶•í•˜ë“œë¦½ë‹ˆë‹¤!  ì—¬ëŸ¬ë¶„ë“¤ì˜ ì„ íƒì´ ê¶ê¸ˆí•œë°ìš” ì–´ë–¤ê±¸ ë§ì´ ì„ íƒí•˜ì˜€ì„ì§€ ê·¸ ê²°ê³¼ë¥¼ ê³µê°œí•©ë‹ˆë‹¤.
"""
# import librosa    // Synthesizerì— í¬í•¨ë˜ì–´ ì œê±°
import soundfile as sf
inference_start = time.time();

i=10
for text in normalize_multiline_text(texts):
    wav = synthesizer.tts(text, None, None)
    # IPython.display.display(IPython.display.Audio(wav, rate=22050))
    # output_name = '/home/kseek/boxboxbox/ChoTTS/output/%d.wav'%(i)
    # sf.write(output_name, wav, 22050)

    output_name = '/home/aiserver/ai/TTS/soundData/%d.wav'%(i)
    sf.write(output_name, wav, 22050)
    i+=1
print("Inference : ",time.time()-inference_start); # 0.2ì´ˆ
print("ğŸ‘‰ total time : ",time.time()-start);
'''

'''
import torch = 0.6
import g2pk = 0.1
synthesizer(glowtts + hifigan) = 0.6
inference = 0.2
0.3 ??

'''
